<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AIアシスタント</title>
    <script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/c-frame/aframe-extras@7.6.0/dist/aframe-extras.min.js"></script>
  </head>
  <body style="margin: 0; overflow: hidden;">
    <a-scene embedded arjs="sourceType: webcam;">
      <a-assets>
        <a-asset-item
          id="buddymodel"
          src="https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Assets/refs/heads/main/Models/CesiumMan/glTF/CesiumMan.gltf"
        ></a-asset-item>
      </a-assets>
      <a-marker preset="hiro">
        <a-entity
          id="cesium-entity"
          gltf-model="#buddymodel"
          animation-mixer=""
          position="0 0 0"
          rotation="0 0 0"
          scale="1 1 1"
        ></a-entity>
      </a-marker>
      <a-entity camera></a-entity>
    </a-scene>
    <script>
      document.addEventListener("DOMContentLoaded", () => {
        const modelEl = document.querySelector("#cesium-entity");
        let isPlaying = false;

        const updateAnimationState = (shouldPlay) => {
          if (!modelEl) {
            return;
          }

          const mixerComponent = modelEl.components["animation-mixer"];
          if (!mixerComponent || !mixerComponent.mixer) {
            return;
          }

          if (isPlaying === shouldPlay) {
            return;
          }

          mixerComponent.mixer.timeScale = shouldPlay ? 1 : 0;
          isPlaying = shouldPlay;
        };

        const initialize = () => {
          updateAnimationState(false);
          let greetingTimeoutId = null;
          let currentUtterance = null;
          let isGreeting = false;

          const cancelGreeting = () => {
            if (greetingTimeoutId) {
              clearTimeout(greetingTimeoutId);
              greetingTimeoutId = null;
            }

            if (speechSynthesis.speaking) {
              speechSynthesis.cancel();
            }

            if (currentUtterance) {
              currentUtterance.onend = null;
              currentUtterance = null;
            }

            if (isGreeting) {
              updateAnimationState(false);
              isGreeting = false;
            }
          };

          const speakGreeting = () => {
            const utterance = new SpeechSynthesisUtterance("こんにちはマスター");
            utterance.lang = "ja-JP";
            utterance.onstart = () => {
              isGreeting = true;
              updateAnimationState(true);
            };
            utterance.onend = () => {
              updateAnimationState(false);
              isGreeting = false;
              currentUtterance = null;
            };
            currentUtterance = utterance;
            speechSynthesis.speak(utterance);
          };

          const scheduleGreeting = () => {
            if (greetingTimeoutId) {
              clearTimeout(greetingTimeoutId);
            }

            greetingTimeoutId = window.setTimeout(() => {
              greetingTimeoutId = null;
              speakGreeting();
            }, 500);
          };

          const SpeechRecognition =
            window.SpeechRecognition || window.webkitSpeechRecognition;
          if (SpeechRecognition) {
            try {
              const recognition = new SpeechRecognition();
              recognition.continuous = true;
              recognition.interimResults = true;
              recognition.onresult = (event) => {
                const lastResult = event.results[event.results.length - 1];
                if (lastResult && lastResult.isFinal) {
                  scheduleGreeting();
                }
              };
              recognition.onspeechstart = () => {
                cancelGreeting();
              };
              recognition.onerror = (event) => {
                console.error("音声認識エラー", event.error);
              };
              recognition.onend = () => {
                try {
                  recognition.start();
                } catch (error) {
                  console.error("音声認識の再開に失敗しました", error);
                }
              };
              recognition.start();
            } catch (error) {
              console.error("音声認識の開始に失敗しました", error);
            }
          } else {
            console.warn("このブラウザはWeb Speech APIに対応していません");
          }
        };

        if (modelEl.hasLoaded) {
          initialize();
        } else {
          modelEl.addEventListener("model-loaded", initialize, { once: true });
        }
      });
    </script>
  </body>
</html>
